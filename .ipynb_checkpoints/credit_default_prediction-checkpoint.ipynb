{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Credit Default Prediction - Advanced Evaluation & Robustness\n",
                "\n",
                "## 1. Introduction\n",
                "**What:** This notebook presents a complete machine learning pipeline to predict credit default risk (Good vs. Bad credit).\n",
                "**Why:** Credit default prediction is crucial for financial institutions to minimize risk and make informed lending decisions.\n",
                "**Goal:** To train and evaluate multiple machine learning models, including advanced Gradient Boosting techniques (XGBoost, LightGBM, CatBoost) and Interpretability-focused models (GAMs).\n",
                "**Advanced Features:**\n",
                "*   **K-Fold Cross-Validation:** For robust performance estimation.\n",
                "*   **Probability Calibration:** To ensure predicted probabilities reflect true risk.\n",
                "*   **Cost-Sensitive Analysis:** Optimizing the decision threshold based on financial costs (False Negatives vs False Positives).\n",
                "*   **Robustness Checks:** Comparing Class Weighting vs. SMOTE Resampling.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Setup and Imports\n",
                "**What:** Importing necessary Python libraries.\n",
                "**Why:** We need `pandas` for data, `sklearn` for modeling, `imblearn` for resampling, and `interpret` for GAMs.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.mixture import GaussianMixture\n",
                "from sklearn.decomposition import PCA\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from catboost import CatBoostClassifier\n",
                "from interpret.glassbox import ExplainableBoostingClassifier\n",
                "from sklearn.metrics import (accuracy_score, roc_auc_score, confusion_matrix, classification_report, \n",
                "                             f1_score, average_precision_score, brier_score_loss, precision_recall_curve)\n",
                "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "\n",
                "# Set visualization style\n",
                "sns.set_style(\"whitegrid\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Loading\n",
                "**What:** Loading the German Credit dataset.\n",
                "**Details:** Defining column names manually as the dataset lacks a header.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define column names\n",
                "columns = [\n",
                "    \"status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
                "    \"savings\", \"employment_duration\", \"installment_rate\", \"personal_status_sex\",\n",
                "    \"other_debtors\", \"residence_since\", \"property\", \"age\", \"other_installment_plans\",\n",
                "    \"housing\", \"existing_credits\", \"job\", \"people_liable\", \"telephone\", \"foreign_worker\",\n",
                "    \"credit_risk\"\n",
                "]\n",
                "\n",
                "def load_data():\n",
                "    filepath = \"dataset.data\"\n",
                "    if not os.path.exists(filepath):\n",
                "        print(f\"Error: {filepath} not found.\")\n",
                "        return None\n",
                "    df = pd.read_csv(filepath, sep=\" \", names=columns, header=None)\n",
                "    return df\n",
                "\n",
                "df = load_data()\n",
                "if df is not None:\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "    display(df.head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Cleaning and Mapping\n",
                "**What:** Mapping cryptic codes to meaningful labels.\n",
                "**Why:** To improve interpretability.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mapping dictionary based on dataset documentation\n",
                "mappings = {\n",
                "    \"status\": {\"A11\": \"< 0 DM\", \"A12\": \"0 <= ... < 200 DM\", \"A13\": \">= 200 DM\", \"A14\": \"no checking\"},\n",
                "    \"credit_history\": {\"A30\": \"no credits/paid\", \"A31\": \"all paid at this bank\", \"A32\": \"existing paid\", \"A33\": \"delay\", \"A34\": \"critical/other\"},\n",
                "    \"purpose\": {\"A40\": \"car (new)\", \"A41\": \"car (used)\", \"A42\": \"furniture/equipment\", \"A43\": \"radio/tv\", \"A44\": \"domestic appliances\", \"A45\": \"repairs\", \"A46\": \"education\", \"A47\": \"vacation\", \"A48\": \"retraining\", \"A49\": \"business\", \"A410\": \"others\"},\n",
                "    \"savings\": {\"A61\": \"< 100 DM\", \"A62\": \"100 <= ... < 500 DM\", \"A63\": \"500 <= ... < 1000 DM\", \"A64\": \">= 1000 DM\", \"A65\": \"unknown/none\"},\n",
                "    \"employment_duration\": {\"A71\": \"unemployed\", \"A72\": \"< 1 year\", \"A73\": \"1 <= ... < 4 years\", \"A74\": \"4 <= ... < 7 years\", \"A75\": \">= 7 years\"},\n",
                "    \"personal_status_sex\": {\"A91\": \"male: divorced/separated\", \"A92\": \"female: div/dep/mar\", \"A93\": \"male: single\", \"A94\": \"male: mar/wid\", \"A95\": \"female: single\"},\n",
                "    \"other_debtors\": {\"A101\": \"none\", \"A102\": \"co-applicant\", \"A103\": \"guarantor\"},\n",
                "    \"property\": {\"A121\": \"real estate\", \"A122\": \"building society/life ins\", \"A123\": \"car/other\", \"A124\": \"unknown/none\"},\n",
                "    \"other_installment_plans\": {\"A141\": \"bank\", \"A142\": \"stores\", \"A143\": \"none\"},\n",
                "    \"housing\": {\"A151\": \"rent\", \"A152\": \"own\", \"A153\": \"for free\"},\n",
                "    \"job\": {\"A171\": \"unemployed/unskilled non-res\", \"A172\": \"unskilled res\", \"A173\": \"skilled\", \"A174\": \"management/self-employed\"},\n",
                "    \"telephone\": {\"A191\": \"none\", \"A192\": \"yes\"},\n",
                "    \"foreign_worker\": {\"A201\": \"yes\", \"A202\": \"no\"}\n",
                "}\n",
                "\n",
                "for col, mapping in mappings.items():\n",
                "    if col in df.columns:\n",
                "        df[col] = df[col].map(mapping).fillna(df[col])\n",
                "\n",
                "print(\"Data cleaning complete.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Preprocessing\n",
                "**What:** Preparing data for modeling.\n",
                "**Steps:**\n",
                "1.  **Target Encoding:** 1 (Good) -> 0, 2 (Bad) -> 1.\n",
                "2.  **Train/Test Split:** 80/20 split.\n",
                "3.  **Preprocessing:** Scaling numericals, One-Hot Encoding categoricals.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode target: 1 (Good) -> 0, 2 (Bad) -> 1\n",
                "df['target'] = df['credit_risk'].apply(lambda x: 0 if x == 1 else 1)\n",
                "\n",
                "X = df.drop(['credit_risk', 'target'], axis=1)\n",
                "y = df['target']\n",
                "\n",
                "categorical_cols = X.select_dtypes(include=['object']).columns\n",
                "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), numerical_cols),\n",
                "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
                "    ])\n",
                "\n",
                "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
                "X_test_preprocessed = preprocessor.transform(X_test)\n",
                "print(f\"Training Set: {X_train.shape[0]}, Test Set: {X_test.shape[0]}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Advanced Evaluation Setup\n",
                "**What:** Defining the models and the evaluation framework.\n",
                "**Key Components:**\n",
                "*   **K-Fold Cross-Validation:** We use 5-fold stratified CV to get a stable estimate of model performance.\n",
                "*   **Probability Calibration:** We apply Isotonic Regression to calibrate probabilities.\n",
                "*   **Metrics:** We track Accuracy, ROC AUC, PR AUC, and Brier Score.\n",
                "*   **Cost Analysis:** We define a custom cost function.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare constraints for XGBoost\n",
                "duration_idx = list(numerical_cols).index('duration')\n",
                "amount_idx = list(numerical_cols).index('credit_amount')\n",
                "n_features = X_train_preprocessed.shape[1]\n",
                "monotone_constraints = [0] * n_features\n",
                "monotone_constraints[duration_idx] = 1\n",
                "monotone_constraints[amount_idx] = 1\n",
                "monotone_constraints = tuple(monotone_constraints)\n",
                "\n",
                "# Define Base Models\n",
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
                "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
                "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
                "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
                "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
                "    \"GAM (EBM)\": ExplainableBoostingClassifier(random_state=42),\n",
                "    \"XGBoost (Constrained)\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, monotone_constraints=monotone_constraints)\n",
                "}\n",
                "\n",
                "# Cost Matrix\n",
                "# Cost(FN) = 5 (Classifying Bad as Good)\n",
                "# Cost(FP) = 1 (Classifying Good as Bad)\n",
                "COST_FN = 5\n",
                "COST_FP = 1\n",
                "\n",
                "def calculate_cost(y_true, y_pred):\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    # cm structure: [[TN, FP], [FN, TP]]\n",
                "    TN, FP, FN, TP = cm.ravel()\n",
                "    return (FN * COST_FN) + (FP * COST_FP)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Training, Calibration, and Evaluation\n",
                "**What:** Training models, calibrating them, and evaluating on the test set.\n",
                "**Why Calibration?** Many models (like Random Forest or Naive Bayes) do not output true probabilities. Calibration (Isotonic/Platt) adjusts the outputs so that a predicted probability of 0.8 actually means 80% of such cases are positive.\n",
                "**Why PR-AUC?** For imbalanced datasets, Precision-Recall AUC is often more informative than ROC AUC.\n",
                "**Why Brier Score?** It measures the accuracy of probabilistic predictions (lower is better).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = {}\n",
                "\n",
                "print(f\"{'Model':<25} | {'Acc':<6} | {'ROC':<6} | {'PR-AUC':<6} | {'Brier':<6} | {'Cost':<6}\")\n",
                "print(\"-\" * 75)\n",
                "\n",
                "for name, model in models.items():\n",
                "    # Handle EBM (raw data) vs others (preprocessed)\n",
                "    if name == \"GAM (EBM)\":\n",
                "        X_curr = X_train\n",
                "        X_test_curr = X_test\n",
                "    else:\n",
                "        X_curr = X_train_preprocessed\n",
                "        X_test_curr = X_test_preprocessed\n",
                "\n",
                "    # 1. Train Base Model\n",
                "    model.fit(X_curr, y_train)\n",
                "    \n",
                "    # 2. Calibrate Model (using CalibratedClassifierCV on pre-fitted model)\n",
                "    # Note: For EBM, it's already well-calibrated usually, but we apply for consistency or skip.\n",
                "    # Here we apply Isotonic calibration.\n",
                "    if name != \"GAM (EBM)\": # EBM has its own calibration\n",
                "        calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv='prefit')\n",
                "        calibrated_model.fit(X_curr, y_train)\n",
                "        final_model = calibrated_model\n",
                "    else:\n",
                "        final_model = model\n",
                "\n",
                "    # 3. Predict Probabilities\n",
                "    y_prob = final_model.predict_proba(X_test_curr)[:, 1]\n",
                "    y_pred = final_model.predict(X_test_curr)\n",
                "    \n",
                "    # 4. Calculate Metrics\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    roc = roc_auc_score(y_test, y_prob)\n",
                "    pr_auc = average_precision_score(y_test, y_prob)\n",
                "    brier = brier_score_loss(y_test, y_prob)\n",
                "    cost = calculate_cost(y_test, y_pred)\n",
                "    \n",
                "    results[name] = {\n",
                "        \"model\": final_model,\n",
                "        \"y_prob\": y_prob,\n",
                "        \"metrics\": {\"acc\": acc, \"roc\": roc, \"pr_auc\": pr_auc, \"brier\": brier, \"cost\": cost}\n",
                "    }\n",
                "    \n",
                "    print(f\"{name:<25} | {acc:.4f} | {roc:.4f} | {pr_auc:.4f} | {brier:.4f} | {cost:<6}\")\n",
                "\n",
                "    # 5. Calibration Curve\n",
                "    CalibrationDisplay.from_predictions(y_test, y_prob, n_bins=10, name=name)\n",
                "    plt.title(f\"Calibration Curve - {name}\")\n",
                "    plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Cost-Sensitive Threshold Optimization\n",
                "**What:** Finding the optimal probability threshold that minimizes the expected financial cost.\n",
                "**Why:** The default threshold of 0.5 is rarely optimal when costs are asymmetric (Cost(FN) = 5 vs Cost(FP) = 1).\n",
                "**Method:** We iterate through thresholds from 0 to 1, calculate the total cost for each, and find the minimum.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_cost_curve(y_true, y_prob, model_name):\n",
                "    thresholds = np.linspace(0, 1, 100)\n",
                "    costs = []\n",
                "    \n",
                "    for t in thresholds:\n",
                "        y_pred_t = (y_prob >= t).astype(int)\n",
                "        costs.append(calculate_cost(y_true, y_pred_t))\n",
                "        \n",
                "    min_cost = min(costs)\n",
                "    best_thresh = thresholds[np.argmin(costs)]\n",
                "    \n",
                "    plt.figure(figsize=(8, 5))\n",
                "    plt.plot(thresholds, costs, label=f'{model_name} (Min Cost: {min_cost})')\n",
                "    plt.axvline(best_thresh, color='r', linestyle='--', label=f'Optimal Thresh: {best_thresh:.2f}')\n",
                "    plt.xlabel('Threshold')\n",
                "    plt.ylabel('Total Cost')\n",
                "    plt.title(f'Expected Cost by Threshold - {model_name}')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "    return min_cost, best_thresh\n",
                "\n",
                "# Analyze Cost for the best performing model (e.g., CatBoost or EBM)\n",
                "best_model_name = \"CatBoost\" # Example choice\n",
                "y_prob_best = results[best_model_name][\"y_prob\"]\n",
                "min_cost, best_thresh = plot_cost_curve(y_test, y_prob_best, best_model_name)\n",
                "print(f\"Optimal Threshold for {best_model_name}: {best_thresh:.2f} with Min Cost: {min_cost}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Robustness: Class Weighting vs. SMOTE\n",
                "**What:** Comparing two techniques to handle class imbalance.\n",
                "**1. Class Weighting:** Assigns higher penalties to misclassifying the minority class directly in the loss function.\n",
                "**2. SMOTE (Synthetic Minority Over-sampling Technique):** Generates synthetic examples for the minority class to balance the dataset.\n",
                "**Why:** To see which method yields better robustness and performance for this specific dataset.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Comparing Class Weighting vs. SMOTE for Random Forest...\")\n",
                "\n",
                "# 1. Class Weighting (Already done in base models)\n",
                "rf_weighted = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "rf_weighted.fit(X_train_preprocessed, y_train)\n",
                "y_pred_w = rf_weighted.predict(X_test_preprocessed)\n",
                "cost_w = calculate_cost(y_test, y_pred_w)\n",
                "print(f\"Class Weighting Cost: {cost_w}\")\n",
                "\n",
                "# 2. SMOTE\n",
                "smote_pipeline = ImbPipeline([\n",
                "    ('smote', SMOTE(random_state=42)),\n",
                "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)) # No class_weight here\n",
                "])\n",
                "smote_pipeline.fit(X_train_preprocessed, y_train)\n",
                "y_pred_s = smote_pipeline.predict(X_test_preprocessed)\n",
                "cost_s = calculate_cost(y_test, y_pred_s)\n",
                "print(f\"SMOTE Cost:           {cost_s}\")\n",
                "\n",
                "if cost_s < cost_w:\n",
                "    print(\"Conclusion: SMOTE performed better.\")\n",
                "else:\n",
                "    print(\"Conclusion: Class Weighting performed better.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Parallel Cross-Validation\n",
                "**What:** Running 5-Fold Stratified Cross-Validation in parallel (`n_jobs=-1`).\n",
                "**Why:** To utilize all CPU cores for faster evaluation and get a statistically robust performance estimate.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Running Parallel Cross-Validation (5-Fold)...\")\n",
                "\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "model_cv = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "\n",
                "# Use cross_validate to get multiple metrics\n",
                "scoring = {'accuracy': 'accuracy', 'roc_auc': 'roc_auc', 'f1': 'f1'}\n",
                "scores = cross_validate(model_cv, X_train_preprocessed, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
                "\n",
                "print(f\"Mean Accuracy: {scores['test_accuracy'].mean():.4f} (+/- {scores['test_accuracy'].std():.4f})\")\n",
                "print(f\"Mean ROC AUC:  {scores['test_roc_auc'].mean():.4f} (+/- {scores['test_roc_auc'].std():.4f})\")\n",
                "print(f\"Mean F1 Score: {scores['test_f1'].mean():.4f} (+/- {scores['test_f1'].std():.4f})\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}